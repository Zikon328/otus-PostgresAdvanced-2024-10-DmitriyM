###  Вопросы к R1

Вот несколько вариантов проектов для исследования PostgreSQL среднего уровня, затрагивающих Patroni, шардирование и оптимизацию:

---

### **1. Высокая доступность с Patroni и автоматическим failover**
**Цель**: Настроить отказоустойчивый кластер PostgreSQL с автоматическим переключением ролей.  
**Шаги**:
- Развернуть 3 ноды (1 мастер, 2 реплики) с Patroni.
- Использовать etcd или Consul как DCS (Distributed Configuration Store).
- Настроить HAProxy/Keepalived для балансировки нагрузки.
- Сымитировать сбой мастера и проверить автоматический переход на реплику.
- Измерить время восстановления и влияние на клиентские подключения.

**Дополнение**: Интеграция с мониторингом (Prometheus + Grafana) для отслеживания состояния кластера.

---

### **2. Шардирование данных с использованием Citus**
**Цель**: Реализовать горизонтальное разделение данных для масштабирования.  
**Шаги**:
- Установить и настроить Citus как расширение PostgreSQL.
- Создать распределенную таблицу с шардированием по хэшу (например, `user_id`).
- Написать скрипт для генерации и вставки тестовых данных (1M+ записей).
- Сравнить производительность запросов (SELECT/INSERT) на шардированной и нешардированной таблицах.
- Реализовать кросс-шардовые запросы (например, агрегацию данных).

**Дополнение**: Добавить репликацию через логический декодирование для шардов.

---

### **3. Оптимизация запросов и настройка индексов**
**Цель**: Улучшить производительность медленных запросов.  
**Шаги**:
- Активировать `pg_stat_statements` для сбора статистики.
- Выявить топ-5 медленных запросов с помощью `EXPLAIN ANALYZE`.
- Оптимизировать их через:
  - Создание составных/частичных индексов.
  - Переписывание запросов (например, устранение N+1).
  - Настройку параметров (work_mem, effective_cache_size).
- Провести бенчмарк до и после изменений (например, с помощью pgbench).

**Дополнение**: Использовать индекс только для покрывающих запросов (Covering Index).

---

### **4. Шардирование + Patroni: Распределенная HA-архитектура**
**Цель**: Объединить шардирование и высокую доступность.  
**Шаги**:
- Развернуть 2 шарда, каждый с кластером Patroni (мастер + реплика).
- Настроить маршрутизатор запросов (например, через приложение или pgpool-II).
- Проверить отказоустойчивость: уронить мастер одного шарда и убедиться, что реплика становится ведущей.
- Протестировать распределение запросов между шардами.

---

### **5. Оптимизация хранилища и VACUUM**
**Цель**: Уменьшить влияние bloat (раздувания) таблиц.  
**Шаги**:
- Создать таблицу с интенсивными UPDATE/DELETE операциями.
- Наблюдать за ростом bloat через `pgstattuple`.
- Настроить автоматический VACUUM с оптимизированными параметрами (autovacuum_vacuum_scale_factor).
- Сравнить размер данных и производительность до/настройки.
- Экспериментировать с табличными пространствами (TABLESPACES) для разделения hot/cold данных.

---

### **6. Миграция данных между шардами**
**Цель**: Реализовать динамическое перераспределение данных.  
**Шаги**:
- Настроить шардированную БД (например, через диапазонное разделение).
- Добавить новый шард и перенести часть данных с существующих шардов.
- Использовать логическую репликацию или инструменты вроде pglogical.
- Обеспечить нулевой даунтайм для приложения.

---

### **7. Нагрузочное тестирование с pgbench + оптимизация**
**Цель**: Найти "узкие места" при высокой нагрузке.  
**Шаги**:
- Сгенерировать тестовую БД с pgbench.
- Запустить нагрузку (read/write) с 100+ параллельными соединениями.
- Анализировать метрики (CPU, I/O, locks) через pg_stat_activity и pg_locks.
- Настроить параметры (max_connections, shared_buffers, checkpoint_timeout).
- Повторить тест и сравнить результаты.

---

### **8. Резервное копирование в распределенной среде**
**Цель**: Реализовать бэкапы для шардированного кластера.  
**Шаги**:
- Настроить WAL-G или pgBackRest для каждого шарда.
- Организовать точки восстановления (PITR) для отдельных шардов.
- Проверить восстановление данных после удаления шарда.

---

### Идеи для комбинированных проектов:
- **Автоматическое масштабирование**: Добавить автоскейлинг шардов в Kubernetes (на базе Patroni и Citus).
- **Геораспределенный кластер**: Настроить шарды в разных регионах с учетом задержек.
- **Оптимизация JOIN в шардированной БД**: Использовать колокацию (colocation) в Citus для ускорения JOIN.

---

Каждый проект можно завернуть в Docker-окружение для упрощения тестирования. Результаты стоит фиксировать в виде отчетов с графиками (например, через Jupyter Notebook).

---

Вот несколько сложных проектов для исследования PostgreSQL, которые требуют углубленного понимания распределенных систем, оптимизации и интеграции различных технологий:

---

### **1. Геораспределенный кластер PostgreSQL с автоматическим балансировкой**
**Цель**: Создать кластер PostgreSQL, распределенный между несколькими регионами (например, EU, US, Asia), с автоматическим переключением ролей и балансировкой запросов.  
**Сложность**:
- Использовать **Patroni** для управления HA в каждом регионе.
- Настроить **Citus** для шардирования данных с учетом географической локации (например, шарды в каждом регионе хранят локальные данные).
- Реализовать **глобальную балансировку** запросов через HAProxy или NGINX с учетом задержек (на основе GeoDNS или Anycast).
- Обеспечить **консистентность данных** между регионами через логическую репликацию с задержкой (например, с использованием **pglogical**).
- Протестировать сценарии: отказ региона, сетевой раскол (split-brain), синхронизация данных.

---

### **2. Динамическое шардирование с автоматическим масштабированием в Kubernetes**
**Цель**: Реализовать автоскейлинг шардов PostgreSQL в Kubernetes на основе нагрузки.  
**Сложность**:
- Развернуть **Citus** в Kubernetes с использованием оператора (например, Zalando Postgres Operator).
- Интегрировать **Patroni** для управления HA внутри каждого шарда.
- Настроить горизонтальное масштабирование (добавление/удаление шардов) через **Custom Metrics API** на основе нагрузки (CPU, IOPS).
- Реализовать **перебалансировку данных** между шардами без простоя (использовать background workers или инструменты вродe **pg_repack**).
- Настроить мониторинг через **Prometheus** и автоматические алерты.

---

### **3. Оптимизация OLAP-нагрузки с использованием параллелизма и аппаратных ускорений**
**Цель**: Достичь максимальной производительности для сложных аналитических запросов.  
**Сложность**:
- Настроить **параллельное выполнение запросов** (max_parallel_workers, work_mem).
- Использовать **колоночные индексы** (cstore_fd) или **BRIN** для временных рядов.
- Интегрировать **GPU-ускорение** через расширения (PG-Strom) для обработки JOIN и агрегаций.
- Сравнить производительность с использованием **NVMe-дисков** и **RDMA** (для сетевых операций).
- Реализовать **распределенные материализованные представления** (связка Citus + материализованные вьюхи).

---

### **4. Реализация Multi-Master в PostgreSQL на основе логической репликации**
**Цель**: Создать Multi-Master кластер с гарантией консистентности.  
**Сложность**:
- Использовать **логическую репликацию** (native или через pglogical) для двусторонней синхронизации.
- Решить проблему конфликтов (UPDATE/DELETE) через **детектирование и разрешение коллизий** (например, с использованием временных меток или кастомных триггеров).
- Настроить **глобальные последовательности** (sequence) через централизованный сервис (например, etcd).
- Обеспечить ACID-гарантии в условиях конкурентной записи.
- Протестировать под нагрузкой (pgbench) с измерением задержек.

---

### **5. Интеграция PostgreSQL с Apache Kafka для потоковой обработки**
**Цель**: Настроить реальную синхронизацию данных между PostgreSQL и Kafka.  
**Сложность**:
- Использовать **Debezium** для захвата изменений из WAL (логическое декодирование).
- Настроить **Kafka Connect** для потоковой передачи данных в Kafka.
- Реализовать обработку событий (например, агрегацию через Kafka Streams).
- Обеспечить **обратную запись** данных из Kafka в PostgreSQL с гарантией идемпотентности.
- Протестировать отказоустойчивость: восстановление после потери сообщений, обработка дубликатов.

---

### **6. Построение гибридной архитектуры: SQL + NoSQL (JSONB + TimescaleDB)**
**Цель**: Объединить реляционные, временные и документоориентированные данные в единой БД.  
**Сложность**:
- Настроить **шардирование** для временных данных через **TimescaleDB**.
- Использовать **JSONB** для хранения неструктурированных данных.
- Оптимизировать индексы (GIN/GIST) для сложных JSONB-запросов.
- Реализовать **гибридные запросы**, объединяющие временные ряды и JSON-данные.
- Сравнить производительность с MongoDB и InfluxDB.

---

### **7. Кастомная оптимизация планировщика запросов**
**Цель**: Модифицировать Planner и Executor для специфических сценариев.  
**Сложность**:
- Анализ статистики через **pg_stat_statements** и **pg_hint_plan**.
- Создать кастомные **плагины планировщика** (на C) для приоритизации определенных типов запросов.
- Реализовать **машинное обучение** для предсказания оптимальных планов (интеграция с Python, сбор данных через **pg_query**).
- Сравнить производительность с оригинальным планировщиком.

---

### **8. Безопасность: шифрование данных и аудит**
**Цель**: Построить защищенный кластер с шифрованием и аудитом.  
**Сложность**:
- Настроить **TDE (Transparent Data Encryption)** через расширения (pgcrypto) или сторонние инструменты.
- Реализовать **аудит изменений** через триггеры или **pgAudit**.
- Интегрировать с **Hashicorp Vault** для управления ключами шифрования.
- Настроить **SSL-сертификаты** с автоматическим ротацием.
- Провести пентест: попытка инъекций, перехват трафика.

---

### **9. Распределенный Consensus: Интеграция Raft в PostgreSQL**
**Цель**: Заменить etcd/Consul в Patroni на кастомную реализацию Raft.  
**Сложность**:
- Реализовать Raft-алгоритм как расширение PostgreSQL (на C или Python).
- Интегрировать его с Patroni для управления лидером.
- Обеспечить обработку сетевых разделов и восстановление.
- Сравнить производительность с etcd.

---

### **10. Реконструкция данных из WAL в реальном времени**
**Цель**: Создать систему восстановления данных на лету из WAL-логов.  
**Сложность**:
- Настроить потоковую передачу WAL в S3/MinIO.
- Реализовать парсер WAL для реконструкции транзакций (на Python/C).
- Создать инструмент для восстановления данных на определенный момент времени без использования PITR.
- Интегрировать с **Apache Arrow** для анализа данных вне PostgreSQL.

---

### **Идеи для супер-сложных проектов**:
- **PostgreSQL как сервис в облаке**: Реализовать аналог AWS RDS с автоматическим масштабированием, бэкапами и мониторингом.
- **Графовая БД на базе PostgreSQL**: Использовать рекурсивные CTE и GIN-индексы для обработки графовых запросов.
- **Интеграция с векторными БД**: Использовать расширения (pgvector) для поиска похожих векторов (ML-модели) + шардирование.

---

Каждый из этих проектов требует не только технических навыков, но и глубокого анализа, проектирования и тестирования. Для реализации можно использовать Docker, Kubernetes, облачные платформы (AWS/GCP) и инфраструктуру как код (Terraform). Результаты стоит оформлять в виде технических статей или докладов с акцентом на преодоленные challenges.

